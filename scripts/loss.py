import torch
import torch.nn as nn
from config.config import logger
from torchvision.ops import sigmoid_focal_loss

class L2ReconstructionLoss(nn.Module):
    def __init__(self, args: dict) -> None:
        """L2ReconstructionLoss for training using inpainting on single images."""
        super(L2ReconstructionLoss, self).__init__()
        self.args = args

    def forward(
        self, prediction: torch.Tensor, target: torch.Tensor, mask: torch.Tensor
    ) -> torch.Tensor:
        """Calculates the L2ReconstructionLoss.

        Args:
            prediction (torch.Tensor): predicted image [BxNxCxHxW]
            target (torch.Tensor): target image [BxNxCxHxW]
            mask (torch.Tensor): mask where the removed image areas are denoted with ones, everything else with zeros [B(xN)xCxHxW]

        Returns:
            torch.Tensor: reconstruction loss as a single value tensor
        """
        assert prediction.shape == target.shape
        assert prediction.shape == mask.shape
        # convert prediction into range [0, 1]
        prediction = torch.sigmoid(prediction)

        # convert target images back into range [0, 1] (unnormalize)
        for channel in range(target.shape[2]):
            target[:, :, channel, :, :] *= float(self.args["normalize_std"][channel])
            target[:, :, channel, :, :] += float(self.args["normalize_mean"][channel])

        # calculate the loss and return it
        out = torch.sub(target, prediction)
        out = torch.mul(out, mask)
        out = torch.square(out)
        out = torch.sum(out)
        return out


class BCEDiceLoss(nn.Module):
    def __init__(self, smooth: float = 1.0) -> None:
        """Initialization

        Args:
            smooth (float, optional): Factor for smoother loss and preventing division by 0. Defaults to 1.0.
        """
        super(BCEDiceLoss, self).__init__()
        self.dice_loss = DiceLoss(smooth = smooth)
        self.BCE_loss = torch.nn.BCEWithLogitsLoss()
        self.threw_warning = False
        #logger.warning(f"LOSS CONFIGURED FOR VACSNET!")


    def forward(self, prediction: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Calculate dice loss and BCE and return the sum

        Args:
            prediction (torch.Tensor): Prediction generated by a model.
            target (torch.Tensor): Ground truth.

        Returns:
            torch.Tensor: Summed BCE and Dice loss
        """
        ################################################
        # ONLY NEEDED FOR VACSNET
        if prediction.shape != target.shape:
            if not self.threw_warning:
                logger.warning("Prediction shape is not equal to target shape. This should only occur while training VACSNet. Target will be downscaled to prediction shape...")
                self.threw_warning = True
            prediction = prediction.reshape(-1, *prediction.shape[2:])
            target = target.reshape(-1, *target.shape[2:])
            target = torch.nn.functional.interpolate(target, scale_factor=(prediction.shape[-1]/target.shape[-1]), mode="bilinear")
        ################################################
        assert prediction.shape == target.shape, f"Got prediction of shape {prediction.shape} but expected shape {target.shape}"
        dice = self.dice_loss(prediction, target)
        bce = self.BCE_loss(prediction, target)
        return dice+bce

class DiceLoss(nn.Module):
    def __init__(self, smooth: float = 1.0) -> None:
        """DiceLoss

        Args:
            smooth (float, optional): smoothing term to avoid division by 1. Defaults to 1.
        """
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, prediction: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Calculate the dice loss.

        Args:
            prediction (torch.Tensor): Prediction by the model.
            target (torch.Tensor): Groundtruth.

        Returns:
            torch.Tensor: dice loss as single value tensor
        """
        assert prediction.shape == target.shape
        # convert prediction into range [0, 1]
        prediction = torch.sigmoid(prediction)

        # calculate intersection (true positive value)
        intersection = torch.mul(prediction, target).sum()

        # calculate the dice score
        dice = (2.0 * intersection + self.smooth) / (prediction.sum() + target.sum() + self.smooth)

        return 1 - dice


class TverskyLoss(nn.Module):
    def __init__(self, alpha: float = 0.7, smooth: float = 1.0) -> None:
        """TverskyLoss

        Args:
            alpha (float, optional): Weight for the false positive value. Defaults to 0.7.
            smooth (float, optional): Smoothing factor to avoid division by 1. Defaults to 1.
        """
        super(TverskyLoss, self).__init__()
        self.alpha = alpha
        self.smooth = smooth

    def forward(self, prediction: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Calculate the TverskyLoss

        Args:
            prediction (torch.Tensor): Prediction generated by the model.
            target (torch.Tensor): Groundtruth.

        Returns:
            torch.Tensor: tversky loss as single value tensor
        """
        assert prediction.shape == target.shape
        # convert prediction into range [0, 1]
        prediction = torch.sigmoid(prediction)

        # calculate true positive, false positive and false negative value
        TP = torch.mul(prediction, target).sum()
        FP = torch.mul((1 - target), prediction).sum()
        FN = torch.mul(target, (1 - prediction)).sum()

        # calculate tversky score
        tversky = (TP + self.smooth) / (TP + self.alpha * FP + (1 - self.alpha) * FN + self.smooth)

        return 1 - tversky


class FocalTverskyLoss(nn.Module):
    def __init__(self, alpha: float = 0.7, gamma: float = 0.75, smooth: float = 1.0) -> None:
        """FocalTverskyLoss

        Args:
            alpha (float, optional): Weight for the false positive value. Defaults to 0.7.
            gamma (float, optional): Exponent applied to the TverskyLoss. Defaults to 0.75.
            smooth (float, optional): Smoothing factor to avoid division by 1. Defaults to 1.
        """
        super(FocalTverskyLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.smooth = smooth

    def forward(self, prediction: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Calculate the FocalTverskyLoss

        Args:
            prediction (torch.Tensor): Prediction generated by the model
            target (torch.Tensor): Groundtruth.

        Returns:
            torch.Tensor: FocalTverskyLoss as single value tensor
        """
        assert prediction.shape == target.shape
        # convert prediction into range [0, 1]
        prediction = torch.sigmoid(prediction)

        # calculate true positive, false positive and false negative value
        TP = torch.mul(prediction, target).sum()
        FP = torch.mul((1 - target), prediction).sum()
        FN = torch.mul(target, (1 - prediction)).sum()

        # calculate the tversky score
        tversky = (TP + self.smooth) / (TP + self.alpha * FP + (1 - self.alpha) * FN + self.smooth)

        return (1 - tversky) ** self.gamma
    
class FocalLoss(nn.Module):
    def __init__(self, smooth: float = 0.0, alpha: float = 0.25, gamma: float = 2.0, reduction: str = "sum") -> None:
        """FocalLoss

        Args:
            alpha (float): Weighting factor to balance positive and negative examples. Defaults to 0.25.
            gamma (float): Weighting factor to balance easy and hard examples. Defaults to 2.0.
            reduction (str): Reduction applied to the output. Valid options are "none", "mean" and "sum". Defaults to "sum".
        """
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, prediction: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Calculates FocalLoss

        Args:
            prediction (torch.Tensor): Prediction generated by the model.
            target (torch.Tensor): Groundtruth.

        Returns:
            torch.Tensor: FocalLoss
        """
        assert prediction.shape == target.shape
        loss = sigmoid_focal_loss(prediction, target, self.alpha, self.gamma, self.reduction)
        return loss

def get_loss(loss: str) -> any:
    if loss == "Dice":
        return DiceLoss
    if loss == "BCE":
        return torch.nn.BCEWithLogitsLoss
    if loss == "Dice+BCE":
        return BCEDiceLoss
    if loss == "Tversky":
        return TverskyLoss
    if loss == "FocalTversky":
        return FocalTverskyLoss
    if loss == "Focal":
        return FocalLoss
    raise ModuleNotFoundError(f"The specified loss module ({loss}) could not be found!")

if __name__ == "__main__":
    WBCE_loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([8]))
    focal_loss = FocalLoss()
    dice_loss = DiceLoss()
    tversky_loss = TverskyLoss()
    focal_tversky_loss = FocalTverskyLoss()

    prediction = torch.randn(1, 5, 3, 256, 256)
    target = torch.sigmoid(torch.randn(1, 5, 3, 256, 256))
    loss = focal_loss(prediction, target)
    print(loss.shape)


